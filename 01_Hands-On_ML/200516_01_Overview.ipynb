{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 신경망과 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9장 텐서플로 시작하기\n",
    "1. 설치\n",
    "2. 첫 번째 계산 그래프를 만들어서 세션에서 실행하기\n",
    "3. 계산 그래프 관리\n",
    "4. 노드 값의 생애주기\n",
    "5. 텐서플로를 이용한 선형 회귀\n",
    "6. 경사 하강법 구현\n",
    "7. 훈련 알고리즘에 데이터 주입\n",
    "8. 모델 저장과 복원\n",
    "9. 텐서보드로 그래프와 학습 곡선 시각화하기\n",
    "10. 이름 범위\n",
    "11. 모듈화\n",
    "12. 변수 공유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10장 인공 신경망 소개\n",
    "1. 생물학적 뉴런에서 인공 뉴런까지\n",
    "2. 텐서플로의 고수준 API로 다층 퍼셉트론 훈련\n",
    "3. 텐서플로의 저수준 API로 심층 신경망 훈련\n",
    "4. 신경망 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11장 심층 신경망 훈련\n",
    "1. 그레디언트 소실과 폭주 문제\n",
    "2. 미리 훈련된 층 재사용하기\n",
    "3. 고속 옵티마이저\n",
    "4. 과대적합을 피하기 위한 규제 방법\n",
    "5. 실용적 가이드라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12장 다중 머신과 장치를 위한 분산 텐서플로\n",
    "1. 단일 머신의 다중 장치\n",
    "2. 다중 머신의 다중 장치\n",
    "3. 텐서플로 클러스터에서 신경망 병렬화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13장 합성곱 신경망, Convolutional neural network (CNN)\n",
    "1. 시각 피질의 구조<br>\n",
    "2. 합성곱층<br>\n",
    "3. 풀링층<br>\n",
    "4. CNN구조<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14장 순환 신경망, Recurrent neural network (RNN)\n",
    "1. 순환 뉴런\n",
    "2. 텐서플로로 기본 RNN 구성\n",
    "3. RNN 훈련\n",
    "4. 심층 RNN\n",
    "5. LSTM 셀\n",
    "6. GRU 셀\n",
    "7. 자연어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15장 오토인코더\n",
    "1. 효율적인 데이터 표현\n",
    "2. 과소완전 선형 오토인코더로 PCA 수행\n",
    "3. 적층 오토인코더\n",
    "4. 적층 오토인코더를 사용한 비지도 사전훈련\n",
    "5. 잡음제거 오토인코더\n",
    "6. 희소 오토인코더\n",
    "7. 변이형 오토인코더\n",
    "8. 다른 오토인코더들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16장 강화 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 보상을 최적화하기 위한 학습\n",
    "2. 정책 탐색\n",
    "3. OpenAI 짐(Gym)\n",
    "4. 신경망 정책\n",
    "5. 행동 평가: 신용 할당 문제\n",
    "6. 정책 그레디언트\n",
    "7. 마르코프 결정 과정\n",
    "8. 시간차 학습과 Q-러닝\n",
    "9. DQN 알고리즘의 미스 팩맨 플레이 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
