{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 기초 정리\n",
    "Reference<br>\n",
    "http://hero4earth.com/blog/learning/2018/01/15/tensor_flow_basics/<br>\n",
    "1. 텐서플로란?\n",
    "2. 텐서플로 용어 (Rnak & Shape)\n",
    "3. 텐서플로 프로세스\n",
    "4. 텐서플로 기본구조\n",
    "5. 텐서플로 기초 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. 텐서플로 기본구조\n",
    "# 1) tf.constant(): 상수\n",
    "# 2) tf.Variable(): 변수\n",
    "# 3) tf.placeholder(): 입력 값을 받을 수 있는 그래프\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(20)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 5. 텐서플로 기초 함수\n",
    "# 1) tf.reduce* (_sum, _mean)\n",
    "\n",
    "# 2) tf.mat* (mul)\n",
    "\n",
    "# 3) tf.cast: 자료형 변환\n",
    "x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
    "tf.cast(x, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack_10:0' shape=(2, 3) dtype=int32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) tf.stack: 값을 쌓아 올려서 배열로 만듦\n",
    "x = [1, 4]\n",
    "y = [2, 5]\n",
    "z = [3, 6]\n",
    "tf.stack([x, y, z], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) one and zero like\n",
    "# tf.ones_like(x): 입력된 shape의 크기로 값을 1로 채워 만들어줌\n",
    "# tf.zeros_like(x): 입력된 shape의 크기로 값을 0으로 채워 만들어줌\n",
    "\n",
    "# 6) tf.equal(x, y): x, y를 비교하여 boolean 값을 반환\n",
    "\n",
    "# 7) tf.argmax(X, a): X 배열에서 가장 큰 값을 '열(1)' 기준 몇번째인지 index를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) tf.nn.softmax: Softmax 함수 적용하여 출력값을 확률 범위로 설정\n",
    "model = tf.nn.softmax(L)\n",
    "\n",
    "# 9) tf.nn.relu(L): relu 함수를 적용하여 출력 값을 0 보다 작을 경우 0, 클경우 x로 설정\n",
    "model = tf.nn.relu(L)\n",
    "\n",
    "# 10) Cross Entropy: 예측값과 실제값 사이의 확률 분포의 차이를 비용으로 계산\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis = 1))\n",
    "\n",
    "# 11) softmax_cross_entropy_with_logits: logits에 softmax와 cross entropy를 한번에 해주는 함수\n",
    "# 직접 계산하는 경우\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * log(hypothesis), axis = 1))\n",
    "# 함수 사용 시: hypothesis가 아니라 Logit을 입력해야함 (Logits > softmax > cross entropy)\n",
    "logits = tf.matmul(X, W) + b\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logtis = logits, labels = Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot_2:0' shape=(4, 1, 3) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12) tf.one_hot: 예측하고자 하는 클래스 갯수가 여러개 일 때 one hot encoding하는 함수\n",
    "tf.one_hot([[0], [1], [2], [0]], depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) tf.reshape: 보통 가장 마지막의 열의 갯수는 고정시키고 rank(차원) 수를 줄일 때 사용\n",
    "tf.reshape(t, shape=[-1, 3])\n",
    "# tf.squeeze: rank를 줄여줌\n",
    "tf.squeeze([[0], [1], [2]]) # => array([0, 1, 2], dtype=int32)\n",
    "# tf.expand: rank를 늘려줌\n",
    "tf.expand_dims([0, 1, 2], 1) # => array([[0], [1], [2]], dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) tf.train.GradientDescentOptimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 15) Session 함수: 작성된 그래프를 실행시키기 위한 세션을 생성\n",
    "sess = tf.Session()\n",
    "sess.run(y_conv, feed_dict={x: image_a, keep_prob: 1})\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
